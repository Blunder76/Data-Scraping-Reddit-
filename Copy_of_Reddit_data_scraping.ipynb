{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efm1OcU8HfLH",
        "outputId": "082611be-e901-4f1b-95d7-f251a44c5c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.1 in /usr/local/lib/python3.10/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.7.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install praw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import praw\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "from tqdm import tqdm\n",
        "import time"
      ],
      "metadata": {
        "id": "1r0mQexoHg2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_date(created):\n",
        "  return dt.datetime.fromtimestamp(created)"
      ],
      "metadata": {
        "id": "6Hu02taLHpam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reddit_connection():\n",
        "  personal_use_script = (\"Your personal script\")\n",
        "  client_secret = (\"Your secret key\")\n",
        "  user_agent = (\"Your agent name\")\n",
        "  username = (\"Your username\")\n",
        "  password = (\"Your password\")\n",
        "\n",
        "  reddit = praw.Reddit(client_id=personal_use_script, \\\n",
        "                       client_secret = client_secret, \\\n",
        "                       user_agent = user_agent, \\\n",
        "                       username=username, \\\n",
        "                       password=''\n",
        "                       )\n",
        "  return reddit"
      ],
      "metadata": {
        "id": "L2o_jP2YHw3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset(reddit, search_words='openai', items_limit=None):\n",
        "  subreddit = reddit.subreddit(search_words)\n",
        "  new_subreddit = subreddit.new(limit=items_limit)\n",
        "  topics_dict = {\"title\":[],\n",
        "                 \"score\":[],\n",
        "                 \"id\":[],\n",
        "                 \"comms_num\":[],\n",
        "                 \"created\":[],\n",
        "                 \"body\":[]}\n",
        "  print(f\"retrieve new reddit posts...\")\n",
        "  for submission in tqdm(new_subreddit):\n",
        "    topics_dict[\"title\"].append(submission.title)\n",
        "    topics_dict[\"score\"].append(submission.score)\n",
        "    topics_dict[\"id\"].append(submission.id)\n",
        "    topics_dict[\"url\"].append(submission.url)\n",
        "    topics_dict[\"comms_num\"].append(submission.num_comments)\n",
        "    topics_dict[\"created\"].append(submission.created)\n",
        "    topics_dict[\"body\"].append(submission.selftext)\n",
        "\n",
        "\n",
        "  for comment in tqdm(subreddit.comments(limit=None)):\n",
        "    topics_dict[\"title\"].append(\"Comment\")\n",
        "    topics_dict[\"score\"].append(comment.score)\n",
        "    topics_dict[\"id\"].append(comment.id)\n",
        "    topics_dict[\"url\"].append(\"\")\n",
        "    topics_dict[\"comms_num\"].append(0)\n",
        "    topics_dict[\"created\"].append(comment.created)\n",
        "    topics_dict[\"body\"].append(comment.body)\n",
        "\n",
        "\n",
        "  topics_df = pd.DataFrame(topics_dict)\n",
        "  print(f\"new reddit posts retrieved: {len(topics_df)}\")\n",
        "\n",
        "  topics_df['timestamp'] = topics_df['created'].apply(lambda x: get_date(x))\n",
        "\n",
        "  return topics_df"
      ],
      "metadata": {
        "id": "BiSddOyTLAOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_and_save_dataset(topics_df):\n",
        "  file_path = \"reddit_dt.csv\"\n",
        "  if os.path.exists(file_path):\n",
        "    topics_old_df = pd.read_csv(file_path)\n",
        "    print(f\"past redit posts: {topics_old_df.shape}\")\n",
        "    topics_all_df = pd.concat([topics_old_df, topics_df], axis=0)\n",
        "    print(f\"new reddit posts: {topics_df.shape[0]} past posts: {topics_old_df.shape[0]} all posts: {topics_all_df.shape[0]}\")\n",
        "    topics_new_df = topics_all_df.drop_duplicates(subset = [\"id\"], keep='last', inplace=False)\n",
        "    print(f\"all reddit posts: {topics_new_df.shape}\")\n",
        "    topics_new_df.to_csv(file_path, index=False)\n",
        "\n",
        "  else:\n",
        "      print(f\"reddit posts: {topics_df.shape}\")\n",
        "      topics_df.to.csv(file_path, index=Fasle)"
      ],
      "metadata": {
        "id": "8k4fA_sUNpDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\treddit = reddit_connection()\n",
        "\ttopics_data_df = build_dataset(reddit)\n",
        "\tupdate_and_save_dataset(topics_data_df)"
      ],
      "metadata": {
        "id": "gJm_PDOTtYsC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}